{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the following implementation was to replicate the research result presented in the Schmid's 1994 paper *Part-of-speech tagging with neural networks* (Schmid, 1994). More specifically, I re-implemented the whole data pipeline to prepared the same format learning data used in the original paper. As for the neural network modeling, since I relied on Keras package to build and train the neural network, I had to make some simplification to the original training architecture. With the architecture specified above, my implementation successfully replicated the original training result. It basically obtained the same model performance as the original implementation.\n",
    "\n",
    "The following discussion divided into two part: first, I walk through the implementation, explaining how I replicated the original data pipeline and specified the neural network architecture. Second, I discuss my training result and compare it to the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **data source and data splitting**\n",
    "\n",
    "The training corpus used in this implementation was the sample corpus of Penn Treebank Corpus provided by the python package NLTK. This sample corpus contained about 3.9K sentences and 10K words. However, not every word in the sample corpus was tagged with one of the 36 part-of-speech tag defined by Penn Treebank Corpus. Therefore, after filtering out those words not tagged with a valid part-of-speech tag, there are about 8.2K words can be used in part-of-speech tagger training. \n",
    "\n",
    "Here I used 80% of words as training data, and among the training data, 90% of words were used to build model and 10% of word were used as validation set. Testing data accounted for 20% of all words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to C:\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to C:\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')\n",
    "from nltk.corpus import treebank\n",
    "from nltk.util import ngrams\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TAG =['CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS','NNP','NNPS','PDT','POS','PRP','PRP$','RB','RBR','RBS','RP','SYM','TO','UH','VB','VBD','VBG','VBN','VBP','VBZ','WDT','WP','WP$','WRB']\n",
    "OPEN_CLASS_POS=['JJ','JJR','JJS','RB','RBR','RBS','NNS','NN','VBZ','VB','VBG','VBP','VBN','VBD']\n",
    "\n",
    "sentences = treebank.tagged_sents()\n",
    "filter_sentences = [[(word, tag) for word, tag in sentence if tag in POS_TAG] for sentence in sentences]\n",
    "\n",
    "all_idx = set(list(range(len(filter_sentences))))\n",
    "train_idx=random.sample(all_idx, k=int(np.ceil(len(filter_sentences)*0.8)))\n",
    "test_idx = all_idx.difference(set(train_idx))\n",
    "\n",
    "val_idx = random.sample(train_idx, k=int(np.ceil(len(train_idx)*0.1)))\n",
    "train_idx = set(train_idx).difference(set(val_idx))\n",
    "\n",
    "train_sentences = [s for idx, s in enumerate(filter_sentences) if idx in train_idx]\n",
    "val_sentences = [s for idx, s in enumerate(filter_sentences) if idx in val_idx]\n",
    "test_sentences = [s for idx, s in enumerate(filter_sentences) if idx in test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **lexicon preparation: fullform lexicon**\n",
    "\n",
    "Lexicon is the sole type of feature we used in this model architecture. According to Schmid, lexicon contains \"the a priori tag probabilities for each word\" (Schmid 1994, pp174). In other word, we can see lexicon as a look-up table, for each word in the lexicon, lexicon stores the probabilities of this word belongs to each part-of-speech tag.\n",
    "\n",
    "Three types of lexicon were used in this architecture. The first type was *fullform lexicon*. According to Schmid ,the algorithm preparing fullform lexicon was straight forward : \"First, the number of occurrences of each word/tag pair was counted. Afterwards, those tags of each word with an estimated probability of less than 1 percent were removed, because they were in most eases the result of tagging errors in the original corpus\" (Schmid, pp174). I implemented fullform lexicon in the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lexicon(g, trim = True):      \n",
    "    if trim:\n",
    "        g = g.loc[g['count']>(g['count'].sum()*0.01), :] \n",
    "    g['prob'] = g['count']/g['count'].sum()\n",
    "    return g\n",
    "\n",
    "def gen_pos_dict(dic):\n",
    "    pos= dict.fromkeys(POS_TAG,0)\n",
    "    pos.update(dic)\n",
    "    return pos\n",
    "\n",
    "# fullform lexicon prepare\n",
    "bag = [{'word':word, 'tag':tag} for s in train_sentences for word, tag in s ]\n",
    "bag = pd.DataFrame(bag)\n",
    "rev_emmission = bag.groupby('word').apply(lambda g: g.groupby('tag').size()).reset_index(name='count')\n",
    "full_lexicon = rev_emmission.groupby('word').apply(get_lexicon).reset_index(drop=True)\n",
    "full_lexicon = full_lexicon.groupby('word').apply(lambda g:gen_pos_dict(dict(zip(g['tag'],g['prob']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **lexicon preparation: suffix lexicon**\n",
    "\n",
    "The second type of lexicon was *suffix lexicon*, which assigned tag probability to a word not base on the word itself but base on the suffix of the word. To build suffix lexicon, first we had to build a suffix tree which stored all possible suffix form that existed in the words tagged with *open class part-of-speech tag* (i.e., noun, verb, adjective, and adverb). We extracted length one to length five suffixes from of those words. Suffixes were organized into parent-child relations according to the **suffix relation between suffixes**. For example, \"s\" is the suffix of \"es\". Therefore node \"s\" is the direct parent of node \"es\" in the suffix tree. The root node of suffix tree was an empty string, and all of other suffixes organized their relation following the suffix relation, formed a suffix tree in the end. \n",
    "\n",
    "Second, using whole training corpus, we calculated tag frequency for every suffix node in the suffix tree. \n",
    "\n",
    "The last step to build suffix tree was pruning. When pruning started, only length-five suffixes were defined as leaf node. **For every leaf node, we calculated it's information gain**, which defined as the information entropy of a leaf node subtracted by its parent node's information entropy, and multiplied the difference by the total frequency of the leaf node. If information gain <10, then the leaf node got deleted. The tag frequency of the deleted leaf node was recollected to a newly created or already existed \"default node\", which was a leaf node of its original parent node. If after an iteration of pruning, a non-leaf node did not have any child or the only child of a non-leaf node was a default node, the non-leaf node itself became a leaf node and (if existed) the default node got pruned. The pruning process started from the lowest level of the suffix tree (length five suffix) and iteratively processed to the top level (length one suffix), until all leaf nodes were being examined. \n",
    "\n",
    "After pruning, we calculated the tag probability for each leaf node. The suffix lexicon was the collection of suffixes' tag probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen suffix tree nodes\n",
    "suffix_tree_nodes = pd.Series([word[::-1] for s in train_sentences for word, tag in s \n",
    "                               if tag in OPEN_CLASS_POS and len(word)>=5]).unique()\n",
    "res = []\n",
    "for i in range(1,6):\n",
    "    res.append(pd.Series([x[:i] for x in suffix_tree_nodes]).unique())\n",
    "suffix_tree_nodes = pd.DataFrame(np.concatenate(res), columns=['suffix'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen suffix tree\n",
    "suffix_bag = pd.DataFrame([{'suffix':word[::-1][:5],'length':len(word[::-1][:5]),'tag': tag} for s in train_sentences for word, tag in s])\n",
    "suffix_tree=[]\n",
    "for i in range(1,6):\n",
    "    temp=suffix_bag.loc[suffix_bag.length>=i].groupby(\n",
    "        lambda idx: suffix_bag.loc[idx,'suffix'][:i]).apply(\n",
    "        lambda g:g.groupby('tag').size()).reset_index(name='count')\n",
    "    temp=temp.rename({'level_0':'suffix'}, axis=1)\n",
    "    temp['level']=i\n",
    "    temp['is_leaf'] = True if i==5 else False\n",
    "    suffix_tree.append(temp)\n",
    "suffix_tree = suffix_tree[0].append(suffix_tree[1:])\n",
    "suffix_tree = suffix_tree.reset_index(drop=True)\n",
    "suffix_tree = suffix_tree_nodes.merge(suffix_tree, on='suffix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finishing pruning for level 5\n",
      "finishing pruning for level 4\n",
      "finishing pruning for level 3\n",
      "finishing pruning for level 2\n",
      "finishing pruning for level 1\n"
     ]
    }
   ],
   "source": [
    "# prune suffix_tree\n",
    "def prun(g,level, ent_table, parent_ent=None):\n",
    "    parent_df  = g.loc[g.level==level,:]\n",
    "    parent = parent_df.iloc[0,0] if level>0 else ''\n",
    "\n",
    "    num_children = len(g.loc[g.level==level+1,'suffix'].unique())\n",
    "    leaf= g.loc[((g.level==level+1) & (g.is_leaf)),:]\n",
    "    non_leaf = g.loc[((g.level==level+1) & (~g.is_leaf)),:]\n",
    "    num_leaf = len(g.loc[((g.level==level+1) & (g.is_leaf)),'suffix'].unique())\n",
    "\n",
    "    # no children\n",
    "    if num_children==0:        \n",
    "        parent_df['is_leaf'] = True\n",
    "        return parent_df\n",
    "    \n",
    "    # have at least one leaf\n",
    "    elif num_leaf>0:\n",
    "        ## calculating information gain and decide if there is any leaf needs to be pruned\n",
    "        leaf_freq= leaf.groupby('suffix').apply(lambda g2:g2['count'].sum()).reset_index(name='freq')\n",
    "        if parent_ent:\n",
    "            leaf_freq['gain'] = leaf_freq.apply(lambda row: row['freq']*(parent_ent-ent_table[row['suffix']]), axis=1)\n",
    "        else:            \n",
    "            leaf_freq['gain'] = leaf_freq.apply(lambda row: row['freq']*(ent_table[parent]-ent_table[row['suffix']]), axis=1)\n",
    "        prune_leaf = leaf_freq.loc[leaf_freq.gain<10,'suffix']\n",
    "            \n",
    "        # all children being drop\n",
    "        if len(prune_leaf)==num_children:\n",
    "            parent_df['is_leaf'] = True\n",
    "            return parent_df\n",
    "        \n",
    "        # some leaf have to be prune\n",
    "        elif len(prune_leaf)>0 and len(prune_leaf)< num_children:\n",
    "            default = leaf.loc[leaf.suffix.isin(prune_leaf),:].groupby('tag').apply(lambda g:g['count'].sum()).reset_index(name='count')\n",
    "            default['suffix'] = parent+'?'\n",
    "            default['level'] = level+1\n",
    "            default['is_leaf'] = True\n",
    "            default = default.reindex(['suffix','tag','count','level','is_leaf'] ,axis=1)\n",
    "            leaf = leaf.loc[~leaf.suffix.isin(prune_leaf),:]\n",
    "            return parent_df.append([leaf, non_leaf, default])\n",
    "        \n",
    "    # all leaf preserved or all children are non_leaf\n",
    "    return g \n",
    "\n",
    "pruned_tree =  suffix_tree\n",
    "ent = suffix_tree.groupby('suffix').apply(lambda g: entropy(g['count']/g['count'].sum(), base=2))\n",
    "root_ent = entropy(bag.tag.value_counts(normalize=True).tolist(),base=2)\n",
    "for i in range(4,-1,-1):\n",
    "    if i==0:\n",
    "        pruned = pruned_tree[pruned_tree['level'].isin([i,i+1])].groupby(\n",
    "                 lambda idx: pruned_tree.loc[idx,'suffix'][:i]).apply(lambda g: prun(g, i, ent, root_ent)).reset_index(drop=True)\n",
    "    else:\n",
    "        pruned = pruned_tree[pruned_tree['level'].isin([i,i+1])].groupby(\n",
    "                 lambda idx: pruned_tree.loc[idx,'suffix'][:i]).apply(lambda g: prun(g,i,ent)).reset_index(drop=True)\n",
    "    print('finishing pruning for level '+ str(i+1))\n",
    "    rest = pruned_tree[~pruned_tree['level'].isin([i,i+1])]\n",
    "    pruned_tree = rest.append(pruned).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen suffix lexicon \n",
    "suffix_lexicon = pruned_tree.loc[pruned_tree.is_leaf,:].groupby('suffix').apply(get_lexicon).reset_index(drop=True)\n",
    "suffix_lexicon = suffix_lexicon.groupby('suffix').apply(lambda g: gen_pos_dict(dict(zip(g['tag'],g['prob'])))).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **lexicon preparation: default entry**\n",
    "\n",
    "The last type of lexicon was *default entry*. The tag frequency we used to calculate tag probability of default entry came from the tag frequency of the suffix tree root node subtracted to the sum of the tag frequencies of all leaf node in the suffix tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# defualt entry\n",
    "leaf_count = pruned_tree.loc[pruned_tree.is_leaf,:].groupby('tag').apply(lambda g:g['count'].sum())\n",
    "root_count = bag.tag.value_counts()\n",
    "default_count = root_count-leaf_count.reindex(root_count.index, fill_value=0)\n",
    "default_count = get_lexicon(pd.DataFrame(default_count, columns=['count']))\n",
    "default_lexicon = gen_pos_dict(dict(zip(default_count.index, default_count['prob'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform corpus to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we generate training data? First, for every word, the training data generate from a six-words context, which consisted of three previous words, the word itself, and two following words.\n",
    "\n",
    "After we identified the context for a word, we searched for the correspond tag probabilities for every word in context. Schmid (1994,pp 174) specified the searching process as follows: \"During the lookup of a word in the lexicon of the Net-Tagger, the fullform lexicon is searched first. If the word is found there, the corresponding tag probability vector is returned. Otherwise, the uppercase letters of the word are turned to lowercase, and the search in the fullform lexicon is repeated. If it fails again, the suffix lexicon is searched next. If none of the previous steps has been successful, the default entry of the lexicon is returned.\"\n",
    "\n",
    "Since every tag probability vector had 36 elements (i.e., 36 kinds of part-of-speech tag) and we returned tag probability vector for all six words in context, every training data was 216 element long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_lexicon_feature(word):\n",
    "    if word is None:\n",
    "        return dict.fromkeys(POS_TAG,0)\n",
    "        \n",
    "    res = {}    \n",
    "    # try to fetch a priori probability in full_form lexicon\n",
    "    if word in full_lexicon or word.lower() in full_lexicon:\n",
    "        #print('from full_lexicon')\n",
    "        w = word if word in full_lexicon else word.lower()\n",
    "        res = full_lexicon[w]            \n",
    "        \n",
    "    # try to fecth a priori probability in suffix lexicon        \n",
    "    else:        \n",
    "        w = word[::-1][:5]\n",
    "        for i in range(len(w),0,-1):\n",
    "            tmp_w = w[:i]\n",
    "            if tmp_w in suffix_lexicon:\n",
    "                #print('from suffix_lexicon')\n",
    "                res = suffix_lexicon[tmp_w]\n",
    "                break\n",
    "            elif tmp_w[:i-1]+'?' in suffix_lexicon:\n",
    "                #print('from suffix_lexicon')\n",
    "                res = suffix_lexicon[tmp_w[:i-1]+'?']\n",
    "                break\n",
    "    \n",
    "    # if the above two approach all failed, return default lexicon\n",
    "    res = res if res else default_lexicon\n",
    "    return res\n",
    "\n",
    "def pick_tag(tags):\n",
    "    tag_idx = [i for i,t in enumerate(tags) if t is not None]\n",
    "    return tags[3] if 3 in tag_idx else None\n",
    "\n",
    "def gen_xy(sentences):\n",
    "    # making ngram \n",
    "    padding =lambda s: ngrams(s, 6, pad_left=True, pad_right=True, left_pad_symbol=(None, None), right_pad_symbol=(None, None))\n",
    "    data = [words for s in sentences for words in padding(s)]\n",
    "    \n",
    "    # mapping data to feature\n",
    "    words = [[w for w,t in word_tuple] for word_tuple in data]\n",
    "    tags = [pick_tag([t for w,t in word_tuple]) for word_tuple in data]\n",
    "    x = [[word_to_lexicon_feature(w) for w in word_list] for idx, word_list in enumerate(words) if tags[idx] is not None]\n",
    "    y = [t for t in tags if t is not None]\n",
    "    print('finishing x,y spliting')\n",
    "    \n",
    "    # reshape\n",
    "    dv= DictVectorizer(sparse=False).fit([dict.fromkeys(POS_TAG,0)])\n",
    "    x = [[dv.fit_transform(dic)[0] for dic in w] for w in x]\n",
    "    x = np.vstack([np.concatenate(w, axis=0) for w in x])\n",
    "    print('finishing x transformation')\n",
    "    y = np.vstack([dv.fit_transform(gen_pos_dict({str(t):1})) for t in y])\n",
    "    print('finishing y transformation')\n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finihsing x,y spliting\n",
      "finishing x transformation\n",
      "finishing y trnasformation\n",
      "finihsing x,y spliting\n",
      "finishing x transformation\n",
      "finishing y trnasformation\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = gen_xy(train_sentences)\n",
    "val_x, val_y = gen_xy(val_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I replicated the original model and training architecture design when it was possible. The architecture was a full-connected neural network with no hidden layer. The Input layer activated by sigmoid function and the output layer activated by softmax function. It was the same architecture I used here. The other training parameters, like epoch, batch size...etc, did not mention in the original paper. Therefore I assigned those training parameter by myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_model(input_dim, hidden_neurons, output_dim):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_neurons, input_dim=input_dim),\n",
    "        Activation('sigmoid'),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_params = {\n",
    "    'build_fn': build_model,\n",
    "    'input_dim': train_x.shape[1],\n",
    "    'hidden_neurons': 512,\n",
    "    'output_dim': train_y.shape[1],\n",
    "    'epochs': 16,\n",
    "    'batch_size': 64,\n",
    "    'verbose': 1,\n",
    "    'validation_data': (val_x, val_y),\n",
    "    'shuffle': True\n",
    "}\n",
    "\n",
    "clf = KerasClassifier(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we found that the part-of-speech predicting accuracy on training data was about 97%, on validation data was about 96.7%, and on testing data was about 96.3%. Since the model performance on training and testing were pretty similar, we can say that there was almost no overfitting problem.\n",
    "\n",
    "The replicated model seemly outperformed the original model. The original model had about 92% accuracy with 60K words training corpus. However, the performance difference may come from the original model**didn't filtered out the words that were tagged with a non-part-of-speech tag**. In other words, the performance difference of replicated and original model may come from that the original model built and tested on a more \"impure\" corpus, which made it harder to produce the right part-of-speech tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59273 samples, validate on 6421 samples\n",
      "Epoch 1/16\n",
      "59273/59273 [==============================] - 8s 134us/step - loss: 0.8211 - acc: 0.8317 - val_loss: 0.2069 - val_acc: 0.9528\n",
      "Epoch 2/16\n",
      "59273/59273 [==============================] - 6s 97us/step - loss: 0.1676 - acc: 0.9573 - val_loss: 0.1508 - val_acc: 0.9601\n",
      "Epoch 3/16\n",
      "59273/59273 [==============================] - 6s 96us/step - loss: 0.1384 - acc: 0.9614 - val_loss: 0.1403 - val_acc: 0.9603\n",
      "Epoch 4/16\n",
      "59273/59273 [==============================] - 6s 104us/step - loss: 0.1286 - acc: 0.9639 - val_loss: 0.1345 - val_acc: 0.9634\n",
      "Epoch 5/16\n",
      "59273/59273 [==============================] - 6s 105us/step - loss: 0.1218 - acc: 0.9653 - val_loss: 0.1305 - val_acc: 0.9626\n",
      "Epoch 6/16\n",
      "59273/59273 [==============================] - 6s 98us/step - loss: 0.1184 - acc: 0.9662 - val_loss: 0.1315 - val_acc: 0.9639\n",
      "Epoch 7/16\n",
      "59273/59273 [==============================] - 6s 99us/step - loss: 0.1150 - acc: 0.9668 - val_loss: 0.1272 - val_acc: 0.9653\n",
      "Epoch 8/16\n",
      "59273/59273 [==============================] - 7s 117us/step - loss: 0.1134 - acc: 0.9668 - val_loss: 0.1363 - val_acc: 0.9623\n",
      "Epoch 9/16\n",
      "59273/59273 [==============================] - 12s 194us/step - loss: 0.1116 - acc: 0.9675 - val_loss: 0.1277 - val_acc: 0.9640\n",
      "Epoch 10/16\n",
      "59273/59273 [==============================] - 6s 98us/step - loss: 0.1097 - acc: 0.9679 - val_loss: 0.1286 - val_acc: 0.9622\n",
      "Epoch 11/16\n",
      "59273/59273 [==============================] - 10s 171us/step - loss: 0.1081 - acc: 0.9684 - val_loss: 0.1293 - val_acc: 0.9646\n",
      "Epoch 12/16\n",
      "59273/59273 [==============================] - 7s 117us/step - loss: 0.1074 - acc: 0.9685 - val_loss: 0.1299 - val_acc: 0.9648\n",
      "Epoch 13/16\n",
      "59273/59273 [==============================] - 6s 109us/step - loss: 0.1059 - acc: 0.9687 - val_loss: 0.1274 - val_acc: 0.9645\n",
      "Epoch 14/16\n",
      "59273/59273 [==============================] - 6s 102us/step - loss: 0.1052 - acc: 0.9689 - val_loss: 0.1308 - val_acc: 0.9642\n",
      "Epoch 15/16\n",
      "59273/59273 [==============================] - 6s 101us/step - loss: 0.1039 - acc: 0.9695 - val_loss: 0.1287 - val_acc: 0.9654\n",
      "Epoch 16/16\n",
      "59273/59273 [==============================] - 6s 100us/step - loss: 0.1036 - acc: 0.9694 - val_loss: 0.1324 - val_acc: 0.9650\n"
     ]
    }
   ],
   "source": [
    "hist = clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finishing x,y spliting\n",
      "finishing x transformation\n",
      "finishing y transformation\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = gen_xy(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16675/16675 [==============================] - 1s 41us/step\n",
      "0.9632383808131697\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(test_x, test_y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helmut Schmid. 1994. Part-of-speech tagging with neural networks. In Proceedings of the 15th conference on Computational linguistics - Volume 1 (COLING '94), Vol. 1. Association for Computational Linguistics, Stroudsburg, PA, USA, 172-176. DOI: https://doi.org/10.3115/991886.991915 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
